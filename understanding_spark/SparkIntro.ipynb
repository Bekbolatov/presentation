{"cells":[{"cell_type":"code","source":["news20 = spark.read.parquet(\"dbfs:/databricks-datasets/news20.binary/data-001/training\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["news20.show()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["news20.groupBy('topic').count().show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["news20.groupBy('label').count().show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.functions import length\n\n# Add a new column 'text_length' that contains the length of data in column 'text'\nnews20_with_lengths = news20.withColumn('text_length', length(news20['text']))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Find average text in each topic\nnews20_with_lengths.groupBy('topic').avg('text_length').orderBy('avg(text_length)').show(truncate = False)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["a"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"SparkIntro","notebookId":4167717899070060},"nbformat":4,"nbformat_minor":0}
